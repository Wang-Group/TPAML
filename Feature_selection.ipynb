{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AFS-LF  \n",
    "## 基于循环拟合的自动特征提取  \n",
    "## Automatic Feature Selection by Loop-Fitting  \n",
    "最后更新：2022.02.07 戴以恒  \n",
    "当前版本：V2.5-Beta-SHAP  \n",
    "### 简介：  \n",
    "通过随机切分、重复拟合，结合特征重要性排名和协方差矩阵进行的包裹式特征提取和数据降维  \n",
    "### 更新记录：  \n",
    "V1.0：框架的搭建  \n",
    "V1.1：改写了回归拟合的部分，将相同的回归器的运行放在了一起(没有性能提升)，改善了画图，修正了特征重要性的归一化方法  \n",
    "V1.2-Alpha：GBRT尝试改为多核并行模式  \n",
    "V1.3-Alpha：增加了最终表现的作图  \n",
    "V1.4-Alpha：修改了排名的算法逻辑  \n",
    "V1.5-Alpha：修改了作图表现，优化性能  \n",
    "V2.0-Beta：实现了GBRT和XGBoost的双并行，可以极大地缩短拟合时间；并更新了最终表现的作图  \n",
    "V2.1-Beta：减少了文件输出量  \n",
    "V2.2-Beta-SHAP：修改了框架，用于使用SHAP输出特征重要性，并引入回归器系数用来调整权重  \n",
    "V2.3-Beta-SHAP：优化了输入输出  \n",
    "V2.4-Beta-SHAP：增加了50以内特征的作图  \n",
    "V2.5-Beta-SHAP：增加输出SHAP分数的非绝对值、非归一化形式，用于直接考察原始特征重要性的影响  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T03:47:15.385725Z",
     "start_time": "2022-05-25T03:47:15.061927Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import gc\n",
    "\n",
    "c_time = time.strftime(\"%Y%m%d_%H%M%S\", time.localtime())\n",
    "c_time_m = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T03:47:15.427824Z",
     "start_time": "2022-05-25T03:47:15.387647Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 参数\n",
    "# ======== System Setup ========\n",
    "Version = 'V2.5-Beta-SHAP'\n",
    "EPOCH = 240\n",
    "REPEAT_ROUND = 1\n",
    "CORE_NUM = 24             # 确保EPOCH*REPEAT_ROUND是CORE_NUM的整数倍\n",
    "TRAIN_TEST_SPLIT = 0.85\n",
    "REGRESSOR_COEF = [0.15, 0.30, 0.55]\n",
    "# ======== Fit Data Input ========\n",
    "S_N = 856\n",
    "F_N = 94\n",
    "INPUT_X = 'Features_'+str(S_N)+'_'+str(F_N)+'.csv'\n",
    "INPUT_Y = 'Values_True_ln_'+str(S_N)+'.csv'\n",
    "INPUT_TITLE = 'Title_'+str(F_N)+'.csv'\n",
    "INPUT_SMILES = 'Smiles_'+str(S_N)+'.csv'\n",
    "ONLY_FIT_ONCE = False\n",
    "INPUT_FEATURE_COUNTS = 'Feature_Counts_'+str(F_N)+'.csv'\n",
    "# ======== Data Output ========\n",
    "RECORD_NAME = 'C01_Record_AFS_'+Version+'_'+c_time+'.txt'\n",
    "LOG_NAME = 'C02_Log_AFS_'+Version+'_'+c_time+'.txt'\n",
    "FIGURE_NAME_1 = 'MSE_Plot_AFS_'+Version\n",
    "FIGURE_NAME_2 = 'R2_Plot_AFS_'+Version\n",
    "FIGURE_NAME_3 = 'MAE_Plot_AFS_'+Version\n",
    "FIGURE_NAME_4 = 'Performance_AFS_'+Version\n",
    "FIGURE_NAME_5 = 'MSE_Distribution_AFS_'+Version\n",
    "FIGURE_NAME_6 = 'R2_Distribution_AFS_'+Version\n",
    "FIGURE_NAME_7 = 'MAE_Distribution_AFS_'+Version\n",
    "FIGURE_NAME_8 = 'Covariance_Matrix_AFS_'+Version\n",
    "FIGURE_NAME_9 = 'XGB_Performance_AFS_'+Version\n",
    "TXT_NAME_1 = 'Feature_Name_AFS_'+Version\n",
    "TXT_NAME_2 = 'Feature_Importance_AFS_'+Version\n",
    "TXT_NAME_3 = 'Covariance_Matrix_AFS_'+Version\n",
    "TXT_NAME_4 = 'Feature_Importance_Sorted_AFS_'+Version\n",
    "TXT_NAME_5 = 'Real_Feature_Importance_Sorted_AFS_'+Version\n",
    "DETAILED_OUTPUT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T03:47:16.661668Z",
     "start_time": "2022-05-25T03:47:15.429761Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn import model_selection\n",
    "import joblib\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T03:47:16.670355Z",
     "start_time": "2022-05-25T03:47:16.663581Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "DIR = 'AFS'+Version+'_'+c_time\n",
    "os.mkdir(DIR)\n",
    "RECORD_NAME = Path('.', DIR, RECORD_NAME)\n",
    "f1 = open(RECORD_NAME, 'w')\n",
    "f1.write('Record of AFS '+Version+'\\n\\n')\n",
    "f1.write('Generation time: '+time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())+'\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T03:47:16.894092Z",
     "start_time": "2022-05-25T03:47:16.671875Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1.write('===Phase 1: Read Dataset===\\n')\n",
    "f1.write('Begin at '+time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())+'\\n')\n",
    "X = np.loadtxt(INPUT_X, delimiter=',')\n",
    "y = np.loadtxt(INPUT_Y)\n",
    "title = np.loadtxt(INPUT_TITLE, dtype=str, delimiter=',', comments='!')\n",
    "smiles = np.loadtxt(INPUT_SMILES, dtype=str, delimiter=',', comments='!')\n",
    "if ONLY_FIT_ONCE:\n",
    "    feature_c = [title.shape[0]]\n",
    "else:\n",
    "    feature_c = np.loadtxt(INPUT_FEATURE_COUNTS, dtype=int).flatten().tolist()\n",
    "f1.write('Shape of dataset: '+str(X.shape)+', '+str(y.shape)+'\\n')\n",
    "f1.write('===Phase 1 done at '+time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())+'===\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T03:47:17.043045Z",
     "start_time": "2022-05-25T03:47:16.895726Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1.write('===Phase 2: Create Regressors===\\n')\n",
    "f1.write('Begin at '+time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())+'\\n')\n",
    "lasso = Lasso(alpha=3.0, max_iter=8000, tol=0.005, selection='random', precompute=False)\n",
    "lasso_para = lasso.get_params()\n",
    "gbrt =GradientBoostingRegressor(n_estimators=200, verbose=0, loss='ls', validation_fraction=0.15, n_iter_no_change=50, tol=0.00025, \n",
    "                                subsample=0.5, warm_start=False,learning_rate=0.045, min_impurity_decrease=0.003972950783280587, \n",
    "                                max_depth=9, max_features=0.2913910225812219, max_leaf_nodes=14)\n",
    "gbrt_para = gbrt.get_params()\n",
    "xgboost = XGBRegressor(n_estimators=150, learning_rate=0.025, max_depth=13, verbosity=0, booster='gbtree', \n",
    "                       reg_alpha=np.exp(-6.788644799030888), reg_lambda=np.exp(-7.450413274554533), gamma=np.exp(-5.374463422208394), \n",
    "                       subsample=0.5, objective= 'reg:squarederror', n_jobs=1)\n",
    "xgb_para = xgboost.get_params()\n",
    "f1.write('Params of Lasso:\\n'+str(lasso_para)+'\\n\\n')\n",
    "f1.write('Params of GBRT:\\n'+str(gbrt_para)+'\\n\\n')\n",
    "f1.write('Params of XGBoost Regressor:\\n'+str(xgb_para)+'\\n\\n')\n",
    "f1.write('===Phase 2 done at '+time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())+'===\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T03:47:17.167805Z",
     "start_time": "2022-05-25T03:47:17.044549Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def draw_distribution(m_in, x_label, title_in, save_name):\n",
    "    global DETAILED_OUTPUT\n",
    "    fig = plt.figure(figsize=(10, 8), dpi=250)\n",
    "    ax = fig.add_axes([0.10, 0.10, 0.84, 0.80])\n",
    "    ax.hist(m_in[:, 0], bins=40, density=False, facecolor='#4682B4', edgecolor='#505050', alpha=0.4)\n",
    "    ax.hist(m_in[:, 1], bins=40, density=False, facecolor='#3CB371', edgecolor='#006400', alpha=0.4)\n",
    "    ax.hist(m_in[:, 2], bins=40, density=False, facecolor='#FF6347', edgecolor='#FF4500', alpha=0.4)\n",
    "    ax.set_xlabel(x_label, fontsize=17)\n",
    "    ax.set_ylabel('Times', fontsize=17)\n",
    "    plt.legend(['Lasso', 'GBRT', 'XGBoost'], loc='upper left', fontsize=16)\n",
    "    plt.suptitle(title_in+'\\nLASSO:'+str(round(np.mean(m_in[:, 0]), 4))+'     GBRT:'+str(round(np.mean(m_in[:, 1]), 4))+\n",
    "                 '     XGBoost:'+str(round(np.mean(m_in[:, 2]), 4)), fontsize=19)\n",
    "    plt.savefig(save_name)\n",
    "    fig.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T03:47:17.284750Z",
     "start_time": "2022-05-25T03:47:17.170553Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def draw_cov(m_in, title_in, save_name, save_name2):\n",
    "    global DETAILED_OUTPUT\n",
    "    m = m_in.copy()\n",
    "    for i in range(m.shape[1]):\n",
    "        m[:, i] = (m[:, i]-np.mean(m[:, i]))/np.std(m[:, i])\n",
    "    cov_m = np.cov(m, rowvar=False)\n",
    "    cov_m -= np.eye(cov_m.shape[0])\n",
    "    if DETAILED_OUTPUT:\n",
    "        np.savetxt(save_name2, cov_m, fmt='%s', delimiter=',')\n",
    "    fig = plt.figure(figsize=(10, 8), dpi=250)\n",
    "    ax = fig.add_axes([0.05, 0.08, 0.90, 0.86])\n",
    "    im = ax.imshow(cov_m, cmap='plasma_r', origin='lower', vmin=-1.0, vmax=1.0)\n",
    "    ax.set_xlabel('Features', fontsize=15)\n",
    "    ax.set_ylabel('Features', fontsize=15)\n",
    "    plt.suptitle(title_in, fontsize=20)\n",
    "    plt.colorbar(im)\n",
    "    plt.savefig(save_name)\n",
    "    fig.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T03:47:17.380735Z",
     "start_time": "2022-05-25T03:47:17.286591Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def LASSO_SHAP(X, clf_new):\n",
    "    shap_values = shap.Explainer(clf_new).shap_values(X)\n",
    "    f_i = np.mean(np.abs(shap_values), axis=0).flatten().tolist()\n",
    "    return f_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T03:47:17.464270Z",
     "start_time": "2022-05-25T03:47:17.382316Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def GBRT_Fit(X, y, X_train, y_train, X_test, y_test, paras):\n",
    "    clf_new = GradientBoostingRegressor()\n",
    "    for k, v in paras.items():\n",
    "        clf_new.set_params(**{k: v})\n",
    "    # print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "    # 拟合模型\n",
    "    clf_new.fit(X_train, y_train)\n",
    "    # 计算损失\n",
    "    y_pred = clf_new.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    shap_values = shap.Explainer(clf_new).shap_values(X)\n",
    "    f_i = np.mean(np.abs(shap_values), axis=0).flatten().tolist()\n",
    "    f_i_o = np.mean(shap_values, axis=0).flatten().tolist()\n",
    "    # f_i = clf_new.feature_importances_\n",
    "    temp = [mse, mae, r2, f_i, f_i_o]\n",
    "    del y_pred, shap_values\n",
    "    return (temp, 'None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T03:47:17.577173Z",
     "start_time": "2022-05-25T03:47:17.465869Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def XGB_Fit(X, y, X_train, y_train, X_test, y_test, paras):\n",
    "    clf_new = XGBRegressor()\n",
    "    for k, v in paras.items():\n",
    "        clf_new.set_params(**{k: v})\n",
    "    # print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "    # 拟合模型\n",
    "    clf_new.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=150, verbose=False)\n",
    "    # 计算损失\n",
    "    y_pred = clf_new.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    shap_values = shap.Explainer(clf_new).shap_values(X)\n",
    "    f_i = np.mean(np.abs(shap_values), axis=0).flatten().tolist()\n",
    "    f_i_o = np.mean(shap_values, axis=0).flatten().tolist()\n",
    "    # f_i = clf_new.feature_importances_\n",
    "    temp = [mse, mae, r2, f_i, f_i_o]\n",
    "    del y_pred, shap_values\n",
    "    return (temp, 'None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T07:56:01.630147Z",
     "start_time": "2022-05-25T03:47:17.578984Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Epoch start with 94 features\n",
      "2 Epoch start with 90 features\n",
      "3 Epoch start with 85 features\n",
      "4 Epoch start with 80 features\n",
      "5 Epoch start with 75 features\n",
      "6 Epoch start with 70 features\n",
      "7 Epoch start with 68 features\n",
      "8 Epoch start with 65 features\n",
      "9 Epoch start with 62 features\n",
      "10 Epoch start with 59 features\n",
      "11 Epoch start with 56 features\n",
      "12 Epoch start with 54 features\n",
      "13 Epoch start with 52 features\n",
      "14 Epoch start with 50 features\n",
      "15 Epoch start with 48 features\n",
      "16 Epoch start with 46 features\n",
      "17 Epoch start with 44 features\n",
      "18 Epoch start with 42 features\n",
      "19 Epoch start with 40 features\n",
      "20 Epoch start with 38 features\n",
      "21 Epoch start with 36 features\n",
      "22 Epoch start with 34 features\n",
      "23 Epoch start with 32 features\n",
      "24 Epoch start with 30 features\n",
      "25 Epoch start with 28 features\n",
      "26 Epoch start with 26 features\n",
      "27 Epoch start with 24 features\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-eac7bcd812d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mr_l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_l\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr_l\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/dyhpy/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mCLOSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTERMINATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"In unknown state\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_worker_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/dyhpy/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/dyhpy/lib/python3.7/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "f1.write('===Phase 3: Fit and Feature Selection===\\n')\n",
    "f1.write('Begin at '+time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())+'\\n')\n",
    "# 初始化最终绘图使用的分数记录矩阵\n",
    "final_mse_m = np.zeros((len(feature_c), 4))\n",
    "final_mae_m = np.zeros((len(feature_c), 4))\n",
    "final_r2_m = np.zeros((len(feature_c), 4))\n",
    "# 初始化排序后的特征序号\n",
    "sort_features = np.linspace(0, title.shape[0]-1, title.shape[0]).astype(int).flatten().tolist()\n",
    "for _ in range(len(feature_c)):\n",
    "    f_c_num = feature_c[_]\n",
    "    print(_+1, 'Epoch start with', f_c_num, 'features')\n",
    "    f1.write('Generation '+str(_+1).zfill(2)+' Begin with '+str(f_c_num)+' Features\\n\\tat '+time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())+'\\n')\n",
    "    s_l = sort_features[:f_c_num]\n",
    "    X = X[:, s_l]\n",
    "    point = round(X.shape[0]*TRAIN_TEST_SPLIT)\n",
    "    save_name = 'A'+str(_+1).zfill(2)+'_01_'+FIGURE_NAME_8+'_'+str(f_c_num)+'_Features.png'\n",
    "    save_name = Path('.', DIR, save_name)\n",
    "    save_name2 = 'A'+str(_+1).zfill(2)+'_02_'+TXT_NAME_3+'_'+str(f_c_num)+'_Features.csv'\n",
    "    save_name2 = Path('.', DIR, save_name2)\n",
    "    draw_cov(X, 'Covariance Matrix of '+str(f_c_num)+' Features', save_name, save_name2)\n",
    "    title = title[s_l, ]\n",
    "    save_name = 'A'+str(_+1).zfill(2)+'_03_'+TXT_NAME_1+'_'+str(f_c_num)+'_Features.csv'\n",
    "    save_name = Path('.', DIR, save_name)\n",
    "    np.savetxt(save_name, title.reshape(title.shape[0], 1), fmt='%s', delimiter=',')\n",
    "    # Lasso使用另一个X\n",
    "    X_L = X.copy()\n",
    "    for i in range(X.shape[1]):\n",
    "        X_L[:, i] = (X_L[:, i]-min(X_L[:, i]))/(max(X_L[:, i])-min(X_L[:, i]))*1000\n",
    "    # 初始化各个回归器的特征系数矩阵\n",
    "    lasso_co = np.zeros((title.shape[0], 1))\n",
    "    gbrt_f_i = np.zeros((title.shape[0], 1))\n",
    "    xgb_f_i = np.zeros((title.shape[0], 1))\n",
    "    # 初始化各个回归器的原始特征系数矩阵\n",
    "    lasso_co_o = np.zeros((title.shape[0], 1))\n",
    "    gbrt_f_i_o = np.zeros((title.shape[0], 1))\n",
    "    xgb_f_i_o = np.zeros((title.shape[0], 1))\n",
    "    # 初始化数据的记录矩阵\n",
    "    mse_m = np.zeros((EPOCH*REPEAT_ROUND, 3))\n",
    "    mae_m = np.zeros((EPOCH*REPEAT_ROUND, 3))\n",
    "    r2_m = np.zeros((EPOCH*REPEAT_ROUND, 3))\n",
    "    # 多轮的训练、拟合\n",
    "    # LASSO\n",
    "    index = -1\n",
    "    for i in range(EPOCH):\n",
    "        permutation = np.random.permutation(y.shape[0])\n",
    "        train_idx = permutation[:point]\n",
    "        test_idx = permutation[point:]\n",
    "        X_train = X[train_idx, :]\n",
    "        y_train = y[train_idx]\n",
    "        X_test = X[test_idx, :]\n",
    "        y_test = y[test_idx]\n",
    "        X_L_train = X_L[train_idx, :]\n",
    "        X_L_test = X_L[test_idx, :]\n",
    "        for j in range(REPEAT_ROUND):\n",
    "            index += 1\n",
    "            if j!=0:\n",
    "                perm_train = np.random.permutation(X_train.shape[0])\n",
    "                X_train = X_train[perm_train, :]\n",
    "                X_L_train = X_L_train[perm_train, :]\n",
    "                y_train = y_train[perm_train]\n",
    "                perm_test = np.random.permutation(X_test.shape[0])\n",
    "                X_test = X_test[perm_test, :]\n",
    "                X_L_test = X_L_test[perm_test, :]\n",
    "                y_test = y_test[perm_test]\n",
    "            # Lasso的回归拟合\n",
    "            lasso_new = Lasso()\n",
    "            for k, v in lasso_para.items():\n",
    "                lasso_new.set_params(**{k: v})\n",
    "            lasso_new.fit(X_L_train, y_train)\n",
    "            y_pred = lasso_new.predict(X_L_test)\n",
    "            mse_m[index, 0] = mean_squared_error(y_test, y_pred)\n",
    "            mae_m[index, 0] = mean_absolute_error(y_test, y_pred)\n",
    "            r2_m[index, 0] = r2_score(y_test, y_pred)\n",
    "            lasso_co = lasso_co+(lasso_new.coef_.reshape(title.shape[0], 1)*r2_m[index, 0])\n",
    "            lasso_co_o = lasso_co_o+(lasso_new.coef_.reshape(title.shape[0], 1)*r2_m[index, 0])\n",
    "            del y_pred\n",
    "    # GBRT\n",
    "    r_l = []\n",
    "    for i in range(int(EPOCH*REPEAT_ROUND/CORE_NUM)):\n",
    "        pool = Pool(CORE_NUM)\n",
    "        for j in range(CORE_NUM):\n",
    "            permutation = np.random.permutation(y.shape[0])\n",
    "            train_idx = permutation[:point]\n",
    "            test_idx = permutation[point:]\n",
    "            X_train = X[train_idx, :]\n",
    "            y_train = y[train_idx]\n",
    "            X_test = X[test_idx, :]\n",
    "            y_test = y[test_idx]\n",
    "            r = pool.apply_async(GBRT_Fit, args=(X, y, X_train, y_train, X_test, y_test, gbrt_para,))\n",
    "            r_l.append(r)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "    for index in range(len(r_l)):\n",
    "        r = r_l[index]\n",
    "        results = r.get()\n",
    "        temp = results[0]\n",
    "        mse_m[index, 1] = temp[0]\n",
    "        mae_m[index, 1] = temp[1]\n",
    "        r2_m[index, 1] = temp[2]\n",
    "        feature_importance = np.array(temp[3]).reshape(title.shape[0], 1)\n",
    "        gbrt_f_i = gbrt_f_i+feature_importance*r2_m[index, 1]\n",
    "        feature_importance_o = np.array(temp[4]).reshape(title.shape[0], 1)\n",
    "        gbrt_f_i_o = gbrt_f_i_o+feature_importance_o*r2_m[index, 1]\n",
    "        del results, temp, feature_importance, feature_importance_o\n",
    "    # XGB\n",
    "    r_l = []\n",
    "    for i in range(int(EPOCH*REPEAT_ROUND/CORE_NUM)):\n",
    "        pool = Pool(CORE_NUM)\n",
    "        for j in range(CORE_NUM):\n",
    "            permutation = np.random.permutation(y.shape[0])\n",
    "            train_idx = permutation[:point]\n",
    "            test_idx = permutation[point:]\n",
    "            X_train = X[train_idx, :]\n",
    "            y_train = y[train_idx]\n",
    "            X_test = X[test_idx, :]\n",
    "            y_test = y[test_idx]\n",
    "            r = pool.apply_async(XGB_Fit, args=(X, y, X_train, y_train, X_test, y_test, xgb_para,))\n",
    "            r_l.append(r)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "    for index in range(len(r_l)):\n",
    "        r = r_l[index]\n",
    "        results = r.get()\n",
    "        temp = results[0]\n",
    "        mse_m[index, 2] = temp[0]\n",
    "        mae_m[index, 2] = temp[1]\n",
    "        r2_m[index, 2] = temp[2]\n",
    "        feature_importance = np.array(temp[3]).reshape(title.shape[0], 1)\n",
    "        xgb_f_i = xgb_f_i + feature_importance*r2_m[index, 2]\n",
    "        feature_importance_o = np.array(temp[4]).reshape(title.shape[0], 1)\n",
    "        xgb_f_i_o = xgb_f_i_o + feature_importance_o*r2_m[index, 2]\n",
    "        del results, temp, feature_importance, feature_importance_o\n",
    "    # 数据记录\n",
    "    for i in range(3):\n",
    "        final_mse_m[_, i] = np.mean(mse_m[:, i])\n",
    "        final_mae_m[_, i] = np.mean(mae_m[:, i])\n",
    "        final_r2_m[_, i] = np.mean(r2_m[:, i])\n",
    "    final_mse_m[_, 3] = (final_mse_m[_, 0]+final_mse_m[_, 1]+final_mse_m[_, 2])/3\n",
    "    final_mae_m[_, 3] = (final_mae_m[_, 0]+final_mae_m[_, 1]+final_mae_m[_, 2])/3\n",
    "    final_r2_m[_, 3] = (final_r2_m[_, 0]+final_r2_m[_, 1]+final_r2_m[_, 2])/3\n",
    "    f1.write('MSE:'+str(final_mse_m[_, :])+'\\n')\n",
    "    f1.write('MAE:'+str(final_mae_m[_, :])+'\\n')\n",
    "    f1.write('R^2:'+str(final_r2_m[_, :])+'\\n')\n",
    "    # 输出数据分布：\n",
    "    if DETAILED_OUTPUT:\n",
    "        save_name = 'A'+str(_+1).zfill(2)+'_04_'+FIGURE_NAME_5+'_'+str(f_c_num)+'_Features.png'\n",
    "        save_name = Path('.', DIR, save_name)\n",
    "        draw_distribution(mse_m, 'MSE', 'MSE Distribution of '+str(f_c_num)+' Features', save_name)\n",
    "        save_name = 'A'+str(_+1).zfill(2)+'_05_'+FIGURE_NAME_7+'_'+str(f_c_num)+'_Features.png'\n",
    "        save_name = Path('.', DIR, save_name)\n",
    "        draw_distribution(mae_m, 'MAE', 'MAE Distribution of '+str(f_c_num)+' Features', save_name)\n",
    "    save_name = 'A'+str(_+1).zfill(2)+'_06_'+FIGURE_NAME_6+'_'+str(f_c_num)+'_Features.png'\n",
    "    save_name = Path('.', DIR, save_name)\n",
    "    draw_distribution(r2_m, 'R^2', 'R^2 Distribution of '+str(f_c_num)+' Features', save_name)\n",
    "    # 特征排列与提取\n",
    "    # 特征归一化\n",
    "    lasso_co[:, 0] = 100.0 * (lasso_co[:, 0]/max(abs(lasso_co[:, 0])))\n",
    "    gbrt_f_i[:, 0] = 100.0 * (gbrt_f_i[:, 0]/max(gbrt_f_i[:, 0]))\n",
    "    xgb_f_i[:, 0] = 100.0 * (xgb_f_i[:, 0]/max(xgb_f_i[:, 0]))\n",
    "    # 输出特征数据\n",
    "    f_out = np.hstack((title.reshape(title.shape[0], 1), np.hstack((lasso_co, np.hstack((gbrt_f_i, xgb_f_i))))))\n",
    "    lasso_co_o = lasso_co_o / np.sum(r2_m[:, 0])\n",
    "    gbrt_f_i_o = gbrt_f_i_o / np.sum(r2_m[:, 1])\n",
    "    xgb_f_i_o = xgb_f_i_o / np.sum(r2_m[:, 2])\n",
    "    f_o_out = np.hstack((title.reshape(title.shape[0], 1), np.hstack((lasso_co_o*1000, np.hstack((gbrt_f_i_o, xgb_f_i_o))))))\n",
    "    # f_out = np.vstack((np.array(['Feature', 'Lasso', 'GBRT', 'XGBoost']).reshape(1, 4), f_out))\n",
    "    if DETAILED_OUTPUT:\n",
    "        save_name = 'A'+str(_+1).zfill(2)+'_07_'+TXT_NAME_2+'_'+str(f_c_num)+'_Features.csv'\n",
    "        save_name = Path('.', DIR, save_name)\n",
    "        np.savetxt(save_name, np.vstack((np.array(['Feature', 'Lasso', 'GBRT', 'XGBoost']).reshape(1, 4), f_out)), fmt='%s', delimiter=',')\n",
    "    # 特征排序\n",
    "    f_i_temp = np.zeros((title.shape[0], 4))\n",
    "    permu_1 = np.argsort(-np.abs(lasso_co).reshape(title.shape[0], ))\n",
    "    permu_2 = np.argsort(-gbrt_f_i.reshape(title.shape[0], ))\n",
    "    permu_3 = np.argsort(-xgb_f_i.reshape(title.shape[0], ))\n",
    "    for i in range(title.shape[0]):\n",
    "        f_i_temp[permu_1[i], 0] = i+1\n",
    "        f_i_temp[permu_2[i], 1] = i+1\n",
    "        f_i_temp[permu_3[i], 2] = i+1\n",
    "    m1 = np.mean(r2_m[:, 0])\n",
    "    m2 = np.mean(r2_m[:, 1])\n",
    "    m3 = np.mean(r2_m[:, 2])\n",
    "    for i in range(title.shape[0]):\n",
    "        f_i_temp[i, 3] = (f_i_temp[i, 0]*(m1*REGRESSOR_COEF[0])+\n",
    "                          f_i_temp[i, 1]*(m2*REGRESSOR_COEF[1])+\n",
    "                          f_i_temp[i, 2]*(m3*REGRESSOR_COEF[2]))/(m1*REGRESSOR_COEF[0]+m2*REGRESSOR_COEF[1]+m3*REGRESSOR_COEF[2])\n",
    "    sort_features = np.argsort(f_i_temp[:, 3]).flatten().tolist()\n",
    "    f_out = f_out[sort_features, :]\n",
    "    f_out = np.hstack((f_out, f_i_temp[sort_features, :]))\n",
    "    save_name = 'A'+str(_+1).zfill(2)+'_08_'+TXT_NAME_4+'_'+str(f_c_num)+'_Features.csv'\n",
    "    save_name = Path('.', DIR, save_name)\n",
    "    np.savetxt(save_name, np.vstack((np.array(['Feature', 'Lasso', 'GBRT', 'XGBoost', 'Lasso Rank', 'GBRT Rank', 'XGBoost Rank', 'Rank']).reshape(1, 8), \n",
    "                                     f_out)), fmt='%s', delimiter=',')\n",
    "    f_o_out = f_o_out[sort_features, :]\n",
    "    f_o_out = np.hstack((f_o_out, f_i_temp[sort_features, :]))\n",
    "    save_name = 'A'+str(_+1).zfill(2)+'_09_'+TXT_NAME_5+'_'+str(f_c_num)+'_Features.csv'\n",
    "    save_name = Path('.', DIR, save_name)\n",
    "    np.savetxt(save_name, np.vstack((np.array(['Feature', 'Lasso', 'GBRT', 'XGBoost', 'Lasso Rank', 'GBRT Rank', 'XGBoost Rank', 'Rank']).reshape(1, 8), \n",
    "                                     f_o_out)), fmt='%s', delimiter=',')\n",
    "    \n",
    "    gc.collect()\n",
    "    f1.write('Generation '+str(_+1).zfill(2)+' Done with '+str(f_c_num)+' Features\\n\\tat '+time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())+'\\n\\n')\n",
    "f1.write('===Phase 3 done at '+time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())+'===\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T07:56:01.640577Z",
     "start_time": "2022-05-25T03:49:08.966Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f1.write('===Phase 4: Draw Full Plots===\\n')\n",
    "f1.write('Begin at '+time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())+'\\n')\n",
    "\n",
    "x_idx = feature_c\n",
    "fig = plt.figure(figsize=(10, 8), dpi=250)\n",
    "ax = fig.add_axes([0.10, 0.10, 0.82, 0.82])\n",
    "ax.plot(x_idx, final_mse_m[:, 0].flatten().tolist(), color=\"#F08080\", linewidth=3, linestyle=':', marker='o', zorder=10)\n",
    "ax.plot(x_idx, final_mse_m[:, 1].flatten().tolist(), color=\"#00CED1\", linewidth=3, linestyle=':', marker='s', zorder=10)\n",
    "ax.plot(x_idx, final_mse_m[:, 2].flatten().tolist(), color=\"#9ACD32\", linewidth=3, linestyle=':', marker='^', zorder=10)\n",
    "ax.plot(x_idx, final_mse_m[:, 3].flatten().tolist(), color=\"#FAA460\", linewidth=3, linestyle=':', marker='*', zorder=10)\n",
    "ax.set_xlabel('Number of Features', fontsize=17)\n",
    "ax.set_ylabel('MSE', fontsize=17)\n",
    "ax.grid(which='major', color='#D5D5D5', alpha=0.5, zorder=1)\n",
    "plt.legend(['Lasso', 'GBRT', 'XGBoost', 'mean'], loc='lower right', fontsize=16)\n",
    "plt.suptitle('MSE - Feature Counts Plot', fontsize=21)\n",
    "save_name = 'B01a_'+FIGURE_NAME_1+'_'+str(len(feature_c))+'_Gens.png'\n",
    "save_name = Path('.', DIR, save_name)\n",
    "plt.savefig(save_name)\n",
    "plt.close()\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8), dpi=250)\n",
    "ax = fig.add_axes([0.10, 0.10, 0.82, 0.82])\n",
    "ax.plot(x_idx, final_mae_m[:, 0].flatten().tolist(), color=\"#F08080\", linewidth=3, linestyle=':', marker='o', zorder=10)\n",
    "ax.plot(x_idx, final_mae_m[:, 1].flatten().tolist(), color=\"#00CED1\", linewidth=3, linestyle=':', marker='s', zorder=10)\n",
    "ax.plot(x_idx, final_mae_m[:, 2].flatten().tolist(), color=\"#9ACD32\", linewidth=3, linestyle=':', marker='^', zorder=10)\n",
    "ax.plot(x_idx, final_mae_m[:, 3].flatten().tolist(), color=\"#FAA460\", linewidth=3, linestyle=':', marker='*', zorder=10)\n",
    "ax.set_xlabel('Number of Features', fontsize=17)\n",
    "ax.set_ylabel('MAE', fontsize=17)\n",
    "ax.grid(which='major', color='#D5D5D5', alpha=0.5, zorder=1)\n",
    "plt.legend(['Lasso', 'GBRT', 'XGBoost', 'mean'], loc='lower right', fontsize=16)\n",
    "plt.suptitle('MAE - Feature Counts Plot', fontsize=21)\n",
    "save_name = 'B01b_'+FIGURE_NAME_3+'_'+str(len(feature_c))+'_Gens.png'\n",
    "save_name = Path('.', DIR, save_name)\n",
    "plt.savefig(save_name)\n",
    "plt.close()\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8), dpi=250)\n",
    "ax = fig.add_axes([0.10, 0.15, 0.80, 0.78])\n",
    "ax.plot(x_idx, final_r2_m[:, 0].flatten().tolist(), color=\"#F08080\", linewidth=3, linestyle=':', marker='o', zorder=10)\n",
    "ax.plot(x_idx, final_r2_m[:, 1].flatten().tolist(), color=\"#00CED1\", linewidth=3, linestyle=':', marker='s', zorder=10)\n",
    "ax.plot(x_idx, final_r2_m[:, 2].flatten().tolist(), color=\"#9ACD32\", linewidth=3, linestyle=':', marker='^', zorder=10)\n",
    "ax.plot(x_idx, final_r2_m[:, 3].flatten().tolist(), color=\"#FAA460\", linewidth=3, linestyle=':', marker='*', zorder=10)\n",
    "ax.set_xlabel('Number of Features', fontsize=17)\n",
    "ax.set_ylabel('R^2', fontsize=17)\n",
    "ax.grid(which='major', color='#D5D5D5', alpha=0.5, zorder=1)\n",
    "plt.legend(['Lasso', 'GBRT', 'XGBoost', 'mean'], loc='lower right', fontsize=16)\n",
    "plt.suptitle('R^2 - Feature Counts Plot', fontsize=21)\n",
    "save_name = 'B01c_'+FIGURE_NAME_2+'_'+str(len(feature_c))+'_Gens.png'\n",
    "save_name = Path('.', DIR, save_name)\n",
    "plt.savefig(save_name)\n",
    "plt.close()\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8), dpi=250)\n",
    "ax1 = fig.add_axes([0.10, 0.07, 0.80, 0.25])\n",
    "ax2 = fig.add_axes([0.10, 0.38, 0.80, 0.25])\n",
    "ax3 = fig.add_axes([0.10, 0.69, 0.80, 0.25])\n",
    "ax1.plot(x_idx, final_mse_m[:, 3].flatten().tolist(), color=\"#F08080\", linewidth=3, linestyle=':', marker='o', zorder=10)\n",
    "ax2.plot(x_idx, final_mae_m[:, 3].flatten().tolist(), color=\"#00CED1\", linewidth=3, linestyle=':', marker='s', zorder=10)\n",
    "ax3.plot(x_idx, final_r2_m[:, 3].flatten().tolist(), color=\"#9ACD32\", linewidth=3, linestyle=':', marker='^', zorder=10)\n",
    "ax1.set_xlabel('Number of Features', fontsize=15)\n",
    "ax1.set_ylabel('MSE', fontsize=15)\n",
    "ax2.set_ylabel('MAE', fontsize=15)\n",
    "ax3.set_ylabel('R^2', fontsize=15)\n",
    "ax1.grid(which='major', color='#D5D5D5', alpha=0.5, zorder=1)\n",
    "ax2.grid(which='major', color='#D5D5D5', alpha=0.5, zorder=1)\n",
    "ax3.grid(which='major', color='#D5D5D5', alpha=0.5, zorder=1)\n",
    "plt.suptitle('AFS '+Version+' Performance Plot', fontsize=19)\n",
    "save_name = 'B01d_'+FIGURE_NAME_4+'_'+str(len(feature_c))+'_Gens.png'\n",
    "save_name = Path('.', DIR, save_name)\n",
    "plt.savefig(save_name)\n",
    "plt.close()\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8), dpi=250)\n",
    "ax1 = fig.add_axes([0.10, 0.07, 0.80, 0.25])\n",
    "ax2 = fig.add_axes([0.10, 0.38, 0.80, 0.25])\n",
    "ax3 = fig.add_axes([0.10, 0.69, 0.80, 0.25])\n",
    "ax1.plot(x_idx, final_mse_m[:, 2].flatten().tolist(), color=\"#F08080\", linewidth=3, linestyle=':', marker='o', zorder=10)\n",
    "ax2.plot(x_idx, final_mae_m[:, 2].flatten().tolist(), color=\"#00CED1\", linewidth=3, linestyle=':', marker='s', zorder=10)\n",
    "ax3.plot(x_idx, final_r2_m[:, 2].flatten().tolist(), color=\"#9ACD32\", linewidth=3, linestyle=':', marker='^', zorder=10)\n",
    "ax1.set_xlabel('Number of Features', fontsize=15)\n",
    "ax1.set_ylabel('MSE', fontsize=15)\n",
    "ax2.set_ylabel('MAE', fontsize=15)\n",
    "ax3.set_ylabel('R^2', fontsize=15)\n",
    "ax1.grid(which='major', color='#D5D5D5', alpha=0.5, zorder=1)\n",
    "ax2.grid(which='major', color='#D5D5D5', alpha=0.5, zorder=1)\n",
    "ax3.grid(which='major', color='#D5D5D5', alpha=0.5, zorder=1)\n",
    "plt.suptitle('AFS '+Version+' XGB Performance Plot', fontsize=19)\n",
    "save_name = 'B02_'+FIGURE_NAME_9+'_'+str(len(feature_c))+'_Gens.png'\n",
    "save_name = Path('.', DIR, save_name)\n",
    "plt.savefig(save_name)\n",
    "plt.close()\n",
    "\n",
    "f1.write('===Phase 4 done at '+time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())+'===\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T07:56:01.643193Z",
     "start_time": "2022-05-25T03:49:08.967Z"
    }
   },
   "outputs": [],
   "source": [
    "if feature_c[0] >= 50:\n",
    "    f1.write('===Phase 5: Draw Last Few Points===\\n')\n",
    "    f1.write('Begin at '+time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())+'\\n')\n",
    "    for i in range(len(feature_c)):\n",
    "        if feature_c[i] <= 50:\n",
    "            bp = i\n",
    "            break\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 8), dpi=250)\n",
    "    ax = fig.add_axes([0.10, 0.10, 0.82, 0.82])\n",
    "    ax.plot(x_idx[bp:], final_mse_m[bp:, 0].flatten().tolist(), color=\"#F08080\", linewidth=3, linestyle=':', marker='o', zorder=10)\n",
    "    ax.plot(x_idx[bp:], final_mse_m[bp:, 1].flatten().tolist(), color=\"#00CED1\", linewidth=3, linestyle=':', marker='s', zorder=10)\n",
    "    ax.plot(x_idx[bp:], final_mse_m[bp:, 2].flatten().tolist(), color=\"#9ACD32\", linewidth=3, linestyle=':', marker='^', zorder=10)\n",
    "    ax.plot(x_idx[bp:], final_mse_m[bp:, 3].flatten().tolist(), color=\"#FAA460\", linewidth=3, linestyle=':', marker='*', zorder=10)\n",
    "    ax.set_xlabel('Number of Features', fontsize=17)\n",
    "    ax.set_ylabel('MSE', fontsize=17)\n",
    "    ax.grid(which='major', color='#D5D5D5', alpha=0.5, zorder=1)\n",
    "    plt.legend(['LASSO', 'GBRT', 'XGB', 'mean'], loc='lower right', fontsize=16)\n",
    "    plt.suptitle('MSE - Feature Counts Plot', fontsize=21)\n",
    "    save_name = 'B03a_'+FIGURE_NAME_1+'_Last_'+str(len(feature_c[bp:]))+'_Gens.png'\n",
    "    save_name = Path('.', DIR, save_name)\n",
    "    plt.savefig(save_name)\n",
    "    plt.close()\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 8), dpi=250)\n",
    "    ax = fig.add_axes([0.10, 0.10, 0.82, 0.82])\n",
    "    ax.plot(x_idx[bp:], final_mae_m[bp:, 0].flatten().tolist(), color=\"#F08080\", linewidth=3, linestyle=':', marker='o', zorder=10)\n",
    "    ax.plot(x_idx[bp:], final_mae_m[bp:, 1].flatten().tolist(), color=\"#00CED1\", linewidth=3, linestyle=':', marker='s', zorder=10)\n",
    "    ax.plot(x_idx[bp:], final_mae_m[bp:, 2].flatten().tolist(), color=\"#9ACD32\", linewidth=3, linestyle=':', marker='^', zorder=10)\n",
    "    ax.plot(x_idx[bp:], final_mae_m[bp:, 3].flatten().tolist(), color=\"#FAA460\", linewidth=3, linestyle=':', marker='*', zorder=10)\n",
    "    ax.set_xlabel('Number of Features', fontsize=17)\n",
    "    ax.set_ylabel('MAE', fontsize=17)\n",
    "    ax.grid(which='major', color='#D5D5D5', alpha=0.5, zorder=1)\n",
    "    plt.legend(['LASSO', 'GBRT', 'XGB', 'mean'], loc='lower right', fontsize=16)\n",
    "    plt.suptitle('MAE - Feature Counts Plot', fontsize=21)\n",
    "    save_name = 'B03b_'+FIGURE_NAME_3+'_Last_'+str(len(feature_c[bp:]))+'_Gens.png'\n",
    "    save_name = Path('.', DIR, save_name)\n",
    "    plt.savefig(save_name)\n",
    "    plt.close()\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 8), dpi=250)\n",
    "    ax = fig.add_axes([0.10, 0.15, 0.80, 0.78])\n",
    "    ax.plot(x_idx[bp:], final_r2_m[bp:, 0].flatten().tolist(), color=\"#F08080\", linewidth=3, linestyle=':', marker='o', zorder=10)\n",
    "    ax.plot(x_idx[bp:], final_r2_m[bp:, 1].flatten().tolist(), color=\"#00CED1\", linewidth=3, linestyle=':', marker='s', zorder=10)\n",
    "    ax.plot(x_idx[bp:], final_r2_m[bp:, 2].flatten().tolist(), color=\"#9ACD32\", linewidth=3, linestyle=':', marker='^', zorder=10)\n",
    "    ax.plot(x_idx[bp:], final_r2_m[bp:, 3].flatten().tolist(), color=\"#FAA460\", linewidth=3, linestyle=':', marker='*', zorder=10)\n",
    "    ax.set_xlabel('Number of Features', fontsize=17)\n",
    "    ax.set_ylabel('R^2', fontsize=17)\n",
    "    ax.grid(which='major', color='#D5D5D5', alpha=0.5, zorder=1)\n",
    "    plt.legend(['Lasso', 'GBRT', 'XGBoost', 'mean'], loc='lower right', fontsize=16)\n",
    "    plt.suptitle('R^2 - Feature Counts Plot', fontsize=21)\n",
    "    save_name = 'B03c_'+FIGURE_NAME_2+'_Last_'+str(len(feature_c[bp:]))+'_Gens.png'\n",
    "    save_name = Path('.', DIR, save_name)\n",
    "    plt.savefig(save_name)\n",
    "    plt.close()\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 8), dpi=250)\n",
    "    ax1 = fig.add_axes([0.10, 0.07, 0.80, 0.25])\n",
    "    ax2 = fig.add_axes([0.10, 0.38, 0.80, 0.25])\n",
    "    ax3 = fig.add_axes([0.10, 0.69, 0.80, 0.25])\n",
    "    ax1.plot(x_idx[bp:], final_mse_m[bp:, 3].flatten().tolist(), color=\"#F08080\", linewidth=3, linestyle=':', marker='o', zorder=10)\n",
    "    ax2.plot(x_idx[bp:], final_mae_m[bp:, 3].flatten().tolist(), color=\"#00CED1\", linewidth=3, linestyle=':', marker='s', zorder=10)\n",
    "    ax3.plot(x_idx[bp:], final_r2_m[bp:, 3].flatten().tolist(), color=\"#9ACD32\", linewidth=3, linestyle=':', marker='^', zorder=10)\n",
    "    ax1.set_xlabel('Number of Features', fontsize=15)\n",
    "    ax1.set_ylabel('MSE', fontsize=15)\n",
    "    ax2.set_ylabel('MAE', fontsize=15)\n",
    "    ax3.set_ylabel('R^2', fontsize=15)\n",
    "    ax1.grid(which='major', color='#D5D5D5', alpha=0.5, zorder=1)\n",
    "    ax2.grid(which='major', color='#D5D5D5', alpha=0.5, zorder=1)\n",
    "    ax3.grid(which='major', color='#D5D5D5', alpha=0.5, zorder=1)\n",
    "    plt.suptitle('AFS '+Version+' Performance Plot', fontsize=19)\n",
    "    save_name = 'B03d_'+FIGURE_NAME_4+'_Last_'+str(len(feature_c[bp:]))+'_Gens.png'\n",
    "    save_name = Path('.', DIR, save_name)\n",
    "    plt.savefig(save_name)\n",
    "    plt.close()\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 8), dpi=250)\n",
    "    ax1 = fig.add_axes([0.10, 0.07, 0.80, 0.25])\n",
    "    ax2 = fig.add_axes([0.10, 0.38, 0.80, 0.25])\n",
    "    ax3 = fig.add_axes([0.10, 0.69, 0.80, 0.25])\n",
    "    ax1.plot(x_idx[bp:], final_mse_m[bp:, 2].flatten().tolist(), color=\"#F08080\", linewidth=3, linestyle=':', marker='o', zorder=10)\n",
    "    ax2.plot(x_idx[bp:], final_mae_m[bp:, 2].flatten().tolist(), color=\"#00CED1\", linewidth=3, linestyle=':', marker='s', zorder=10)\n",
    "    ax3.plot(x_idx[bp:], final_r2_m[bp:, 2].flatten().tolist(), color=\"#9ACD32\", linewidth=3, linestyle=':', marker='^', zorder=10)\n",
    "    ax1.set_xlabel('Number of Features', fontsize=15)\n",
    "    ax1.set_ylabel('MSE', fontsize=15)\n",
    "    ax2.set_ylabel('MAE', fontsize=15)\n",
    "    ax3.set_ylabel('R^2', fontsize=15)\n",
    "    ax1.grid(which='major', color='#D5D5D5', alpha=0.5, zorder=1)\n",
    "    ax2.grid(which='major', color='#D5D5D5', alpha=0.5, zorder=1)\n",
    "    ax3.grid(which='major', color='#D5D5D5', alpha=0.5, zorder=1)\n",
    "    plt.suptitle('AFS '+Version+' XGB Performance Plot', fontsize=19)\n",
    "    save_name = 'B02_'+FIGURE_NAME_9+'_Last_'+str(len(feature_c[bp:]))+'_Gens.png'\n",
    "    save_name = Path('.', DIR, save_name)\n",
    "    plt.savefig(save_name)\n",
    "    plt.close()\n",
    "    \n",
    "    f1.write('===Phase 5 done at '+time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())+'===\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T07:56:01.645944Z",
     "start_time": "2022-05-25T03:49:08.967Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f1.write('\\n\\n   AFS-LF Done Normally at '+time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())+'\\n\\n\\n')\n",
    "f1.close()\n",
    "LOG_NAME = Path('.', DIR, LOG_NAME)\n",
    "f2 = open(LOG_NAME, 'w')\n",
    "f2.write('Log of AFS-LF '+Version+'\\n')\n",
    "f2.write('Log generation time: '+time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())+'\\n\\n')\n",
    "f2.write('Input data:\\n')\n",
    "f2.write('Feature Matrix: '+INPUT_X+'\\n')\n",
    "f2.write('Label Values: '+INPUT_Y+'\\n')\n",
    "f2.write('Smiles List: '+INPUT_SMILES+'\\n')\n",
    "f2.write('Title List: '+INPUT_TITLE+'\\n')\n",
    "f2.write('Feature Count List: '+INPUT_FEATURE_COUNTS+'\\n\\n')\n",
    "f2.write('Parameters:\\n')\n",
    "f2.write('Total Generation: '+str(len(feature_c))+'\\n')\n",
    "f2.write('Epoch of every Generation: '+str(EPOCH)+'\\n')\n",
    "f2.write('Round of every Epoch: '+str(REPEAT_ROUND)+'\\n')\n",
    "f2.write('Split Ratio of Training and Testing Sets: '+str(TRAIN_TEST_SPLIT)+'\\n')\n",
    "f2.write('Accumulating Coef of Regressors: LASSO: '+str(REGRESSOR_COEF[0])+' GBRT:'+str(REGRESSOR_COEF[1])+' XGB:'+str(REGRESSOR_COEF[2])+'\\n')\n",
    "f2.write('Params of Regressors:\\n')\n",
    "f2.write('Params of Lasso:\\n'+str(lasso_para)+'\\n\\n')\n",
    "f2.write('Params of GBRT:\\n'+str(gbrt_para)+'\\n\\n')\n",
    "f2.write('Params of XGBoost Regressor:\\n'+str(xgb_para)+'\\n\\n')\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonForDYH",
   "language": "python",
   "name": "dyhpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
